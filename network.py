import tensorflow as tf
from tensorflow.contrib.layers import xavier_initializer


class UNet:
    """Defines architercure of the unet autoencoder"""

    def __init__(self, activation, is_training):
        """
        :param activation: Activation function
        :param is_training: placeholder needed for batch normalization
        """
        self.activation = activation
        self.is_training = is_training

    def encoder(self, inputs, activation, is_training):
        """Encoder part of the network. Uses shortcut connections for Unet architecture"""
        with tf.variable_scope('encoder', reuse=tf.AUTO_REUSE, initializer=xavier_initializer()):
            batch_size = tf.shape(inputs)[0]

            conv1 = tf.layers.conv2d(inputs, 48, 3, padding='same', activation=None)
            conv1 = tf.layers.batch_normalization(conv1, training=is_training, fused=True)
            conv1 = activation(conv1)
            conv1 = tf.layers.max_pooling2d(conv1, 2, 2)

            shortcut1 = tf.get_variable('shortcut1', shape=[1, 64, 64, 48], dtype=tf.float32)
            shortcut1 = tf.tile(shortcut1, [batch_size, 1, 1, 1])
            shortcut1 = tf.nn.sigmoid(conv1 * shortcut1)

            conv2 = tf.layers.conv2d(conv1, 92, 3, padding='same', activation=None)
            conv2 = tf.layers.batch_normalization(conv2, training=is_training, fused=True)
            conv2 = activation(conv2)
            conv2 = tf.layers.max_pooling2d(conv2, 2, 2)

            shortcut2 = tf.get_variable('shortcut2', shape=[1, 32, 32, 92], dtype=tf.float32)
            shortcut2 = tf.tile(shortcut2, [batch_size, 1, 1, 1])
            shortcut2 = tf.nn.sigmoid(conv2 * shortcut2)

            conv3 = tf.layers.conv2d(conv2, 256, 3, padding='same', activation=None, name='econv3')
            conv3 = tf.layers.batch_normalization(conv3, training=is_training, fused=True)
            conv3 = activation(conv3)
            conv3 = tf.layers.max_pooling2d(conv3, 2, 2)

            shortcut3 = tf.get_variable('shortcut3', shape=[1, 16, 16, 256], dtype=tf.float32)
            shortcut3 = tf.tile(shortcut3, [batch_size, 1, 1, 1])
            shortcut3 = tf.nn.sigmoid(conv3 * shortcut3)

            conv4 = tf.layers.conv2d(conv3, 256, 3, padding='same', activation=None)
            conv4 = tf.layers.batch_normalization(conv4, training=is_training, fused=True)
            conv4 = activation(conv4)
            conv4 = tf.layers.max_pooling2d(conv4, 2, 2)

            conv5 = tf.layers.conv2d(conv4, 256, 3, padding='same', activation=None)
            conv5 = tf.layers.batch_normalization(conv5, training=is_training, fused=True)
            conv5 = activation(conv5)
            conv5 = tf.layers.max_pooling2d(conv5, 2, 2)

            conv6 = tf.layers.conv2d(conv5, 256, 3, padding='same', activation=None)
            conv6 = tf.layers.batch_normalization(conv6, training=is_training, fused=True)
            conv6 = activation(conv6)
            conv6 = tf.layers.max_pooling2d(conv6, 2, 2)

            conv_features = tf.layers.flatten(conv6)
            return conv_features, (shortcut1, shortcut2, shortcut3)

    def latent_space(self, conv_features, angles, activation):
        """Merges features extracted by conv layers with information about desired output angles"""
        dense1 = tf.layers.dense(angles, 512)
        dense1 = tf.layers.dense(dense1, 512, activation)

        dense2 = tf.concat([conv_features, dense1], -1)
        dense2 = tf.layers.dense(dense2, 1024, activation)
        dense2 = tf.layers.dense(dense2, 16384, activation)

        return dense2

    def decoder(self, merged_view_conv, activation, is_training, shortcuts):
        """Decoder network. Uses shortcuts generated by encoder"""
        with tf.variable_scope('decoder', reuse=tf.AUTO_REUSE, initializer=xavier_initializer()):
            shortcut1, shortcut2, shortcut3 = shortcuts

            pre_conv = tf.reshape(merged_view_conv, [-1, 8, 8, 256])
            pre_conv = tf.image.resize_images(pre_conv, (16, 16))
            pre_conv = tf.concat([pre_conv, shortcut3], axis=-1)

            conv1 = tf.layers.conv2d(pre_conv, 256, 3, padding='same', activation=None)
            conv1 = tf.layers.batch_normalization(conv1, training=is_training, fused=True)
            conv1 = activation(conv1)
            conv1 = tf.image.resize_images(conv1, (32, 32))
            conv1 = tf.concat([conv1, shortcut2], axis=-1)

            conv2 = tf.layers.conv2d(conv1, 92, 3, padding='same', activation=None)
            conv2 = tf.layers.batch_normalization(conv2, training=is_training, fused=True)
            conv2 = activation(conv2)
            conv2 = tf.image.resize_images(conv2, (64, 64))
            conv2 = tf.concat([conv2, shortcut1], axis=-1)

            conv3 = tf.layers.conv2d(conv2, 48, 3, padding='same', activation=None)
            conv3 = tf.layers.batch_normalization(conv3, training=is_training, fused=True)
            conv3 = activation(conv3)
            conv3 = tf.image.resize_images(conv3, (128, 128))

            generated_rgb = tf.layers.conv2d(conv3, 3, 3, padding='same', activation=None)

            return generated_rgb

    def network(self, base_images, target_angles):
        """Composes full network from encoder, latent and decoder modules"""
        encoder_features, shortcuts = self.encoder(base_images, self.activation, self.is_training)
        view_encoder_merged = self.latent_space(encoder_features, target_angles, self.activation)
        generated_images = self.decoder(view_encoder_merged, self.activation, self.is_training, shortcuts)
        return generated_images
